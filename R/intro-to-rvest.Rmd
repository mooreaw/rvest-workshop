---
title: "A brief introduction to web scraping using `rvest`"
author: "Andrew Moore"
date: "`r format(Sys.Date(), '%m-%d-%Y')`"
output: html_document
---

```{r opts, include = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

## Outline

- *What are our goals?*
    - Basic introduction to web scraping
    - Just enough of the R language to grasp the basics
    - Be able to follow along with a program designed to get data from the internet

- *What is web scraping?*
    - Discuss good practice, robots.txt
    - HTML elements, XPaths, looking at a website's 'source'

- *Web scraping in R*
    - Give a quick overview of the R environment, data types
    - Discuss the primary functions used with the `rvest` package
    
- *Applied example: gathering job postings from labor.gov*

## What is web scraping?

- Going beyond copy/paste

- Using software to systematically gather data from websites
    - Copying information posted online for later review/analysis
    - Can be done manually
    - Or through an automated process ("crawlers", "bots", "spiders")

- Lots of terms & names for describing the same thing:
    - "web scraping" or "scraping"
    - "web harvesting"

## Good practice & responsible scraping

- Read each website's ToS and policies
    - May not be permissible for you to scrape certain data
        - copyright laws
        - trespassing
        - violation of the computer fraud and abuse act (CFAA)
    - Can get your IP Address banned
        - make you sad
        - make your institution mad
    - Public data generally okay to gather, but be conscious
    - Reaching out to web administrators is often a good idea
- Read each website's robots.txt
    - Example: https://en.wikipedia.org/robots.txt
    - How to understand a robots.txt file: https://en.wikipedia.org/wiki/Robots_exclusion_standard
    - Not all websites have a robots.txt file, but it's good to check
        - typically found right at the top of the website's directory: https://www.websitename.com/robots.txt/

## Using R: packages & workspace (0/4)

Note: I really hope you've installed the most recent version of [R](https://cloud.r-project.org/) & [RStudio](https://www.rstudio.com/products/rstudio/#Desktop) on your computer.

- 'packages' are bundles of code that other people have written for convenient use later
- they contain functions and data that are meant to be used across different projects
- start by running the following command in your console:
    - `install.packages("tidyverse")`

```{r init}
# install packages once, load packages every session
# installing *is not the same* as loading 
# load packages by calling the `library()` function on a package name
library(tidyverse)
```

## Using R: data types (1/4)

Quick look at how data is stored and represented in R (you can use the `class()` function on an object to find out what it is)

- *vectors*
    - can be thought of single columns of a spreadsheet
    - most basic type of data
    - one dimensional: length (how many items in the vector)
    - only one type of data contained in them
        - numeric (numbers, either integer values or decimals)
        - character (text based data)
        - logical (`TRUE` or `FALSE`)
        - missing values (represented by `NA` in R)
        - factor (won't cover in detail, just be aware they exist)
    - if you try to mix different types, R will try to convert ("coerce") them into a compatible type

- *lists*
    - a little more advanced
    - used to store sets of vectors or other forms of data (even lists of lists!)
    - you can store as many items in a list as you want
    - each item in the list can be a different type of data
    - and have different dimensions (rows, lengths, etc.)

- *data frames*
    - technically data frames are lists, but they probably feel more familiar
    - rows and columns (2 dimensions)
    - we <3 data frames

## Using R: data types (2/4)

```{r use-r-2}
# vectors
letters[1:12]

# lists
list(my_letters = letters[1:5], my_numbers = 1:10)

# data frames
head(mpg)
```

## Using R: operators (3/4)

Operators. One note: `#` marks lines as comments

```{r ops-1}
# creating sequences using the colon
1:5

5:1

# doing math
3 * 2

1 + 1

3 - 2

4 / 8

4 ^ 2

1:10 - 1 # you can perform operations over vectors too!
```

```{r ops-2} 
# logical tests
2 == 2

2 != 4

TRUE & FALSE

TRUE | FALSE

# storing data as variables for later use
# <- is the *assignment operator*
x <- 3
y <- 22

(x * y) + 4

# getting data out of an object
mpg_cty <- mpg$cty
```

## Using R: functions (4/4)

- Just like we learned in school, functions have *names*, and take *arguments*
- Arguments go inside parentheses

```{r functions, warning = TRUE}
mean(mpg_cty) # find an average of a vector of data
mean(letters) # can't find the average of the alphabet...

table(mpg$class) # the $ operator can be used to access columns in data frames
```

```{r eval = FALSE}
# ? can be used to pull up help pages about functions, or built-in data
?mean
```

## The `rvest` package

We're going to look at the wikipedia entry for the [gini coefficient](https://en.wikipedia.org/wiki/Gini_coefficient) as an example. We'll use the 'inspect' feature from the chrome browser to look at the structure of the page to get an XPath that can be targeted by functions from `rvest`.

```{r rvest-1}
# load the rvest package that came installed with the `tidyverse` bundle
library(rvest)

# grab the html from the web
gini <- read_html("https://en.wikipedia.org/wiki/Gini_coefficient")

# after we've looked at the page's source, we can get the xpath we want
tabl <- html_nodes(gini, xpath = '//*[@id="mw-content-text"]/div/table[1]')

html_text(tabl)  # a little more work might be needed
html_table(tabl) # but, this is actually a table, so we can take a shortcut
```

## More to `rvest`, but these are the main pieces

You can do a lot more to automate processes with `rvest` (like submitting data into forms, or pulling out more complicated information from HTML files), but we won't need to go into too much more detail.

I've gotten most projects done with the following:

- `read_html()`
- `html_node()` or `html_nodes()`
- `html_text()` or `html_table()`

## An applied example: getting H-2A postings from the DoL

We have an example link for Kenzie's project. After using Selectorgadget on the page, we can find out the xpath for the elements we want to extract.

```{r}
library(lubridate)

link <- "https://lcr-pjr.doleta.gov/index.cfm?event=ehLCJRExternal.dspJobOrderView&frm=lcjr&task=view_job_order&view=external&lcjr_id=123105"

xpath <- "//p | //h5"

# get the html
html <- read_html(link)

# get the areas we want
node <- html_nodes(html, xpath = xpath)

# pull out the text!
text <- html_text(node)

# let's look at the text
text[1:10]
```

Kind of messy! It looks like we have some nonsense information as our first element-- all the spaces and `\t\r\n` stuff. It also looks like the data that is normally organized horizontally on the actual page has been turned into a stack of information. E.g. `"Job Registry Record ID:"` and its associated value, `"123105 "`, should probably be on the same line, but instead they've been split across two. Let's check the bottom of the data to make sure nothing else weird is going on.

```{r}
tail(text, n = 10)
```

Okay, we pulled out the whole paragraph of information about the wage rates, which I think was supposed to happen. It also looks like the stuff at the bottom is formatted the same as the stuff at the top (i.e. it's the same configuration, field name followed by the associated value on a new line). This is good, because it means we can pluck it out in a pretty straightforward way.

```{r}
# drop the first piece
# do some minor cleaning of the text
text <- text[-1]

# this gets rid of extra spaces at the front/end of each line
text <- str_trim(text)

# if a line is blank, let's treat it as missing data
text[text == ""] <- NA

# we're doing integer division with the %% operator (%% is pronounced 'modulo')
# example: 5 %% 2
# the fields are odds
field <- text[1:length(text) %% 2 == 1]

# the data are evens
dats  <- text[1:length(text) %% 2 == 0]

# place in a data frame
df <- data_frame(
  field = field,
  dat   = dats
)

# functions from the stringr package
# fields end with a colon-- strip those off
# clean up the spaces/punctuation
df$field <- df$field %>%
  str_to_lower() %>%
  str_replace(":", "") %>%
  str_replace_all("[[:punct:]]", "") %>%
  str_replace_all("  ", " ") %>%
  str_replace_all(" ", "_")

# tall to wide
# use parse_guess() to turn the all number fields into R's numeric class
# convert all the dates
df <- df %>%
  spread(field, dat) %>%
  map_df(parse_guess) %>%
  mutate_at(vars(contains("date")), funs(mdy(.)))
```

Now we'll take the code we worked through above, and put it into a more regularized function. It'll take two arguments, a URL and the appropriate XPath, as characters.

```{r as a function}
job_getter <- function(url, xpath) {
  # get the data
  txt <- url %>%
    read_html() %>%
    html_nodes(xpath = xpath) %>%
    html_text()
  
  # clean the text
  txt <- str_trim(txt)
  txt <- txt[-1]
  txt[txt == ""] <- NA
  
  # put the data frame together
  out <-
    data_frame(
      field = txt[1:length(txt) %% 2 == 1],
      dat   = txt[1:length(txt) %% 2 == 0]
    ) %>%
    mutate(
      field = field %>%
        str_to_lower() %>%
        str_replace(":", "") %>%
        str_replace_all("[[:punct:]]", "") %>%
        str_replace_all("  ", " ") %>%
        str_replace_all(" ", "_")
    ) %>%
    spread(field, dat) %>%
    map_df(parse_guess) %>%
    mutate_at(vars(contains("date")), funs(mdy(.))) %>%
    mutate_at(vars(contains("zip")), funs(as.character))
  
  # be nice to the website!
  Sys.sleep(4)
  
  # return it
  out
}

test0 <- job_getter(link, xpath)

# can we get more than one page?
test1 <- job_getter("https://lcr-pjr.doleta.gov/index.cfm?event=ehLCJRExternal.dspJobOrderView&frm=lcjr&task=view_job_order&view=external&lcjr_id=124004", xpath = xpath)
test2 <- job_getter("https://lcr-pjr.doleta.gov/index.cfm?event=ehLCJRExternal.dspJobOrderView&frm=lcjr&task=view_job_order&view=external&lcjr_id=123442", xpath = xpath)

done <- bind_rows(test0, test1, test2)

# print the results
done[1:3, 39:41]
```
